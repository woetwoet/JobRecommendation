{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Profile Vacancies recommendation engine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Context\n",
    "\n",
    "The notebook has been created in the context of a a \"Postgraduate Studies in Big Data & Analytics in Business and Management\". \n",
    "\n",
    "It has been based on the blog post https://towardsdatascience.com/if-you-cant-measure-it-you-can-t-improve-it-5c059014faad, \n",
    "I modified it a bit to cater for my own dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "from VacancyData import VacancyData\n",
    "from VacancyHelper import helper\n",
    "\n",
    "from lightfm.data import Dataset\n",
    "from lightfm import LightFM\n",
    "\n",
    "from lightfm.cross_validation import random_train_test_split\n",
    "from lightfm.evaluation import auc_score\n",
    "from lightfm.evaluation import precision_at_k\n",
    "from lightfm.evaluation import recall_at_k\n",
    "from lightfm.evaluation import reciprocal_rank\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data part\n",
    "qd = VacancyData();\n",
    "\n",
    "matchings, vacancies, profiles, profilestest = qd.getData()\n",
    "\n",
    "# Creating a dataset    \n",
    "dataset = Dataset()\n",
    "dataset.fit((x['ProfielId'] for x in qd.getMatchings()),\n",
    "            (x['VacatureId'] for x in qd.getMatchings()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Interaction set : Num users: 3, num_items 6. ---\n"
     ]
    }
   ],
   "source": [
    "# Check on items and users in our interactions set\n",
    "num_users, num_items = dataset.interactions_shape()\n",
    "print('--- Interaction set : Num users: {}, num_items {}. ---'.format(num_users, num_items))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Total set : Num users: 11361, num_items 8356. ---\n"
     ]
    }
   ],
   "source": [
    "# Adding the vacancy features in the mix\n",
    "dataset.fit_partial(items=(x['VacatureId'] for x in qd.getVacancies()),\n",
    "                    item_features=(x['Naam'] for x in qd.getVacancies()))\n",
    "\n",
    "dataset.fit_partial(items=(x['VacatureId'] for x in qd.getVacancies()),\n",
    "                    item_features=(x['Taal'] for x in qd.getVacancies()),\n",
    "                    )\n",
    "\n",
    "dataset.fit_partial(items=(x['VacatureId'] for x in qd.getVacancies()),\n",
    "                    item_features=(x['Functie'] for x in qd.getVacancies()),\n",
    "                    )\n",
    "# Adding the user features in the mix. TODO: make a feature list for users (other then just motivation)\n",
    "dataset.fit_partial(users=(x['Id'] for x in qd.getProfiles()),\n",
    "                    user_features=(x['Motivatie'] for x in qd.getProfiles())                    \n",
    "                    )\n",
    "num_users, num_items = dataset.interactions_shape()\n",
    "print('--- Total set : Num users: {}, num_items {}. ---'.format(num_users, num_items))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating the interaction matrix for the model\n",
    "(interactions, weights) = dataset.build_interactions(((x['ProfielId'], x['VacatureId'])\n",
    "                                                      for x in qd.getMatchings()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating the item feature matrix for the model\n",
    "item_features = dataset.build_item_features(((x['VacatureId'], [x['Naam'],x['Taal'],x['Functie']])\n",
    "                                              for x in qd.getVacancies()),normalize=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the set in train and test\n",
    "test , train = random_train_test_split(interactions, test_percentage=0.2, random_state=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Start model training ---\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<lightfm.lightfm.LightFM at 0x25cd57a4da0>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Start training the model\n",
    "print(\"--- Start model training ---\")\n",
    "model=LightFM(no_components=5,learning_rate=0.027,loss='warp')\n",
    "model.fit(train,item_features=item_features, epochs=100,num_threads=4, verbose=False)\n",
    "# model.fit(train,epochs=12,num_threads=4)\n",
    "\n",
    "modelnofeatures=LightFM(no_components=5,learning_rate=0.027,loss='warp')\n",
    "modelnofeatures.fit(train, epochs=100,num_threads=4, verbose=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Start model evaluation ---\n",
      "--- End model evaluation. Run time:  0.9939277569452921 mins ---\n",
      "Auc: train 1.00, test 0.88.\n",
      "Precision: train 0.28, test 0.01.\n",
      "Recall: train 0.53, test 0.02.\n",
      "--- End model evaluation model no features. Run time:  1.5767034848531087 mins ---\n",
      "Auc: train 1.00, test 0.85.\n",
      "Precision: train 0.53, test 0.01.\n",
      "Recall: train 1.00, test 0.02.\n"
     ]
    }
   ],
   "source": [
    "# Start evaluation of the model\n",
    "print(\"--- Start model evaluation ---\")\n",
    "# Default k is 10. K is top N in which the precision or recall is measured.\n",
    "topN = 5\n",
    "start_time = time.time()\n",
    "\n",
    "auc_train = auc_score(model, train,item_features=item_features).mean()\n",
    "auc_test = auc_score(model, test,item_features=item_features).mean()\n",
    "precision_train = precision_at_k(model, train, k=topN, item_features=item_features).mean()\n",
    "precision_test = precision_at_k(model, test, k=topN, item_features=item_features).mean()\n",
    "recall_train = recall_at_k(model, train,k=topN, item_features=item_features).mean()\n",
    "recall_test = recall_at_k(model, test,k=topN, item_features=item_features).mean()\n",
    "\n",
    "print(\"--- End model evaluation. Run time:  {} mins ---\".format((time.time() - start_time)/60))\n",
    "\n",
    "print('Auc: train %.2f, test %.2f.' % (auc_train, auc_test))\n",
    "print('Precision: train %.2f, test %.2f.' % (precision_train, precision_test))\n",
    "print('Recall: train %.2f, test %.2f.' % (recall_train, recall_test))\n",
    "\n",
    "auc_trainnf = auc_score(modelnofeatures, train).mean()\n",
    "auc_testnf = auc_score(modelnofeatures, test).mean()\n",
    "precision_trainnf = precision_at_k(modelnofeatures, train, k=topN).mean()\n",
    "precision_testnf = precision_at_k(modelnofeatures, test, k=topN).mean()\n",
    "recall_trainnf = recall_at_k(modelnofeatures, train,k=topN).mean()\n",
    "recall_testnf = recall_at_k(modelnofeatures, test,k=topN).mean()\n",
    "\n",
    "print(\"--- End model evaluation model no features. Run time:  {} mins ---\".format((time.time() - start_time)/60))\n",
    "\n",
    "print('Auc: train %.2f, test %.2f.' % (auc_trainnf, auc_testnf))\n",
    "print('Precision: train %.2f, test %.2f.' % (precision_trainnf, precision_testnf))\n",
    "print('Recall: train %.2f, test %.2f.' % (recall_trainnf, recall_testnf))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manual testing\n",
    "ratingspd = pd.DataFrame(matchings)\n",
    "ratingspd['rating']=ratingspd.apply(lambda row:'1', axis=1)\n",
    "\n",
    "user_item_matrix = ratingspd.pivot(index='ProfielId', columns='VacatureId', values='rating')\n",
    "user_item_matrix.fillna(0, inplace = True)\n",
    "user_item_matrix = user_item_matrix.astype(np.int32)\n",
    "\n",
    "itemspd = pd.DataFrame(vacancies)\n",
    "\n",
    "user_dikt, item_dikt = helper.user_item_dikts(user_item_matrix, itemspd)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The user has not applied for a job yet...\n",
      "Recommended Jobs:\n",
      "1- SECRÉTAIRE H/F\n",
      "2- EMPLOYÉ CALL-CENTER (H/F)\n",
      "3- CHAUFFEUR B\n"
     ]
    }
   ],
   "source": [
    "# Generate recommendations for the user without an interaction\n",
    "# helper.similar_recommendation(model, user_item_matrix, '4666', user_dikt, item_dikt,threshold = 0)\n",
    "helper.similar_recommendation_features(model, user_item_matrix, '166', item_dikt,dataset,interactions,item_features,threshold = 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jobs that are chosen by the user:\n",
      "1- EMPLOYÉ ADMINISTRATIF\n",
      "Recommended Jobs:\n",
      "1- SECRÉTAIRE\n",
      "2- STUDENT - BOUCHERIE\n",
      "3- ETUDIANT NETTOYEUR\n"
     ]
    }
   ],
   "source": [
    "helper.similar_recommendation_features(model, user_item_matrix, '1134', item_dikt,dataset,interactions,item_features,threshold = 0)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
